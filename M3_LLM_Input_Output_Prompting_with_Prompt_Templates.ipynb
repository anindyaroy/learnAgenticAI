{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anindyaroy/learnAgenticAI/blob/main/M3_LLM_Input_Output_Prompting_with_Prompt_Templates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVraWpDTW8i0"
      },
      "source": [
        "# Prompting with Prompt Templates for LLM Input / Output with LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1KvMtf54l0d"
      },
      "source": [
        "## Install OpenAI and LangChain dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_cdzB8v0o3O",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Updated package versions for compatibility:\n",
        "# !pip install langchain==0.3.21\n",
        "# !pip install langchain-openai==0.3.9\n",
        "# !pip install langchain-community==0.3.19\n",
        "\n",
        "!pip install langchain==0.3.26\n",
        "!pip install langchain-openai==0.3.28\n",
        "!pip install langchain-community==0.3.27"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtBa7rlWJWH3"
      },
      "source": [
        "## Enter API Tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6RD7As2sm8G"
      },
      "source": [
        "#### Enter your Open AI Key here\n",
        "\n",
        "You can get the key from [here](https://platform.openai.com/api-keys) after creating an account or signing in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JQcY7Kew0o3Q",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cKlax-updNW-",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4h0xywyJ3v7"
      },
      "source": [
        "## Chat Models and LLMs\n",
        "\n",
        "Large Language Models (LLMs) are a core component of LangChain. LangChain does not implement or build its own LLMs. It provides a standard API for interacting with almost every LLM out there.\n",
        "\n",
        "There are lots of LLM providers (OpenAI, Hugging Face, etc) - the LLM class is designed to provide a standard interface for all of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSdF6_R7J45Z"
      },
      "source": [
        "## Accessing Commercial LLMs like ChatGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "v8nnrOGxZ2uZ",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Updated parameter name from model_name to model:\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i8KIVTwnD6Y"
      },
      "source": [
        "## Prompt Templates\n",
        "Prompt templates are pre-designed formats used to generate prompts for language models. These templates can include instructions, few-shot examples, and specific contexts and questions suited for particular tasks.\n",
        "\n",
        "LangChain provides tools for creating and using prompt templates. It aims to develop model-agnostic templates to facilitate the reuse of existing templates across different language models. Typically, these models expect prompts in the form of either a string or a list of chat messages.\n",
        "\n",
        "### Types of Prompt Templates\n",
        "\n",
        "- **PromptTemplate:**\n",
        "  - Used for creating string-based prompts.\n",
        "  - Utilizes Python's `str.format` syntax for templating, supporting any number of variables, including scenarios with no variables.\n",
        "\n",
        "- **ChatPromptTemplate:**\n",
        "  - Designed for chat models, where the prompt consists of a list of chat messages.\n",
        "  - Each chat message includes content and a role parameter. For instance, in the OpenAI Chat Completions API, a chat message could be assigned to an AI assistant, a human, or a system role.\n",
        "- **FewShotChatMessagePromptTemplate**\n",
        "  - A few-shot prompt template can be constructed from a set of examples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Oh9UiTNqaPf"
      },
      "source": [
        "### PromptTemplate\n",
        "\n",
        "We can use `PromptTemplate` to create a template for a string prompt.\n",
        "\n",
        "By default, `PromptTemplate` uses Python's `str.format` syntax for templating.\n",
        "\n",
        "You can create custom prompt templates that format the prompt in any way you want. For more information, see [Prompt Template Composition](https://python.langchain.com/v0.1/docs/modules/model_io/prompts/composition/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xoUCbb4FkaIW",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Simple prompt\n",
        "\n",
        "prompt = \"\"\"Explain to me what is Generative AI in 3 bullet points?\"\"\"\n",
        "prompt_template = PromptTemplate.from_template(prompt)\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nPNs1Efsn2Zf",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "prompt_template.format()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iM5oNvXpnSq7",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "response = chatgpt.invoke(prompt_template.format())\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2VTvciVcnajD",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# more complex prompt with placeholders\n",
        "prompt = \"\"\"Explain to me briefly about {topic} in {language}.\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate.from_template(prompt)\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FyXhUhbapZ7T",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "inputs = [(\"Generative AI\", \"english\"),\n",
        "          (\"Artificial Intelligence\", \"hindi\"),\n",
        "          (\"Deep Learning\", \"german\")]\n",
        "\n",
        "prompts = [prompt_template.format(topic=topic, language=language) for topic, language in inputs]\n",
        "prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "edPyCf_Aps9Q",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# use map to run on multiple prompts in one go\n",
        "responses = chatgpt.map().invoke(prompts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wZ8cDck4ck_g",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tRWUf9eTqEMU",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-----')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAGmjR-tqfmV"
      },
      "source": [
        "### ChatPromptTemplate\n",
        "\n",
        "The standard prompt format to [chat models](https://python.langchain.com/v0.1/docs/modules/model_io/chat/) is a list of [chat messages](https://python.langchain.com/v0.1/docs/modules/model_io/chat/message_types/).\n",
        "\n",
        "Each chat message is associated with content, and an additional parameter called `role`. For example, in the OpenAI Chat Completions API, a chat message can be associated with an AI assistant, a human or a system role."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tawdWLueqHG6",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Updated import paths for prompt templates - using simplified paths:\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# simple prompt with placeholders\n",
        "prompt = \"\"\"Explain to me briefly about {topic}.\"\"\"\n",
        "\n",
        "chat_template = ChatPromptTemplate.from_template(prompt)\n",
        "chat_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Hr0sC7xHqxOp",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "topics = ['mortgage', 'fractional real estate', 'commercial real estate']\n",
        "prompts = [chat_template.format(topic=topic) for topic in topics]\n",
        "prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cU9YObv9rY4P",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "responses = chatgpt.map().invoke(prompts)\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-----')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8NHhUa48rm_g",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "responses[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1PSkafcfsme2",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# more complex prompt with a series of messages\n",
        "messages = [\n",
        "        (\"system\", \"Act as an expert in real estate and provide brief answers\"),\n",
        "        (\"human\", \"what is your name?\"),\n",
        "        (\"ai\", \"my name is AIBot\"),\n",
        "        (\"human\", \"{user_prompt}\"),\n",
        "]\n",
        "chat_template = ChatPromptTemplate.from_messages(messages)\n",
        "chat_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "N5ncYrVVtUWU",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "text_prompts = [\"what is your name?\",\n",
        "                \"explain commercial real estate to me\"]\n",
        "chat_prompts = [chat_template.format(user_prompt=prompt) for prompt in text_prompts]\n",
        "chat_prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vQd1Bk_Td2mM",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "print(chat_prompts[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xQnrzTfj59gv",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "print(chat_prompts[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "73R370WTuAIR",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "responses = chatgpt.map().invoke(chat_prompts)\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-----')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qQJP-Q6SuLmV",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "        (\"system\", \"Act as an expert in real estate and provide very detailed answers with examples\"),\n",
        "        (\"human\", \"what is your name?\"),\n",
        "        (\"ai\", \"my name is AIBot\"),\n",
        "        (\"human\", \"{user_prompt}\"),\n",
        "]\n",
        "chat_template = ChatPromptTemplate.from_messages(messages)\n",
        "text_prompts = [\"what is your name?\", \"explain commercial real estate to me\"]\n",
        "chat_prompts = [chat_template.format(user_prompt=prompt) for prompt in text_prompts]\n",
        "chat_prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JK9VxeObuTXj",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "responses = chatgpt.map().invoke(chat_prompts)\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-----')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PnxbHHoiDHZ"
      },
      "source": [
        "#### PromptTemplate and ChatPromptTemplate supports LCEL\n",
        "\n",
        "`PromptTemplate` and `ChatPromptTemplate` implement the [Runnable interface](https://python.langchain.com/v0.1/docs/expression_language/interface/), the basic building block of the LangChain Expression Language (LCEL). This means they support `invoke`, `ainvoke`, `stream`, `astream`, `batch`, `abatch`, `astream_log` calls.\n",
        "\n",
        "`PromptTemplate` accepts a dictionary (of the prompt variables) and returns a `StringPromptValue`. A `ChatPromptTemplate` accepts a dictionary and returns a `ChatPromptValue`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Qxsx7a0xe2u6",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "text_prompts = [\"what is your name?\", \"explain commercial real estate to me\"]\n",
        "chat_prompts = [chat_template.invoke({'user_prompt' : prompt}) for prompt in text_prompts]\n",
        "chat_prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tCqy3Exuiuu0",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "chat_prompts[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wND5o7kCiyKG",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "print(chat_prompts[1].to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "egsNrmqui6ls",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "chat_prompts[1].to_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "r_ywweDLflCq",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "responses = chatgpt.map().invoke(chat_prompts)\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-----')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmNqkwlGPLPU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}